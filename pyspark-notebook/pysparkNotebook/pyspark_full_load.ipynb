{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import SparkContext\n",
    "from os.path import abspath\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "\n",
    "# import findspark\n",
    "# findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"pyspark app test\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .config(\"spark.jars\", \"/Users/hmakhlouf/Desktop/TechCnsltng_WorkSpace/config/postgresql-42.7.2.jar\") \\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://ip-172-31-3-80.eu-west-2.compute.internal:8889\") \\\n",
    "    .getOrCreate()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1- Establish the connection to PostgresSQL and read data from the postgres Database -testdb\n",
    "# PostgresSQL connection properties\n",
    "postgres_url = \"jdbc:postgresql://ec2-3-9-191-104.eu-west-2.compute.amazonaws.com:5432/testdb\"\n",
    "postgres_properties = {\n",
    "    \"user\": \"consultants\",\n",
    "    \"password\": \"WelcomeItc@2022\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "postgres_table_name = \"car_insurance_claims\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/13 16:46:02 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+----+--------+----+-------+-------+--------+-------+------+------------+-------------+--------+-------+--------+---+----------+-------+--------+--------+-------+-------+-------+-------+----------+--------------------+\n",
      "|       ID|KIDSDRIV|  BIRTH| AGE|HOMEKIDS| YOJ| INCOME|PARENT1|HOME_VAL|MSTATUS|GENDER|   EDUCATION|   OCCUPATION|TRAVTIME|CAR_USE|BLUEBOOK|TIF|  CAR_TYPE|RED_CAR|OLDCLAIM|CLM_FREQ|REVOKED|MVR_PTS|CLM_AMT|CAR_AGE|CLAIM_FLAG|          URBANICITY|\n",
      "+---------+--------+-------+----+--------+----+-------+-------+--------+-------+------+------------+-------------+--------+-------+--------+---+----------+-------+--------+--------+-------+-------+-------+-------+----------+--------------------+\n",
      "|501699878|       0|31DEC58|40.0|       1|16.0|$66,987|     No|$236,897|    Yes|   z_F|   Bachelors|      Manager|      28|Private| $12,200| 13|Sports Car|     no|  $8,216|       3|     No|      6|     $0|   11.0|         0| Highly Urban/ Urban|\n",
      "|624637727|       0|17NOV40|58.0|       0|14.0|$20,473|     No|      $0|   z_No|   z_F|   Bachelors|   Home Maker|      52|Private| $17,850|  1|   Minivan|     no|      $0|       0|     No|      0|     $0|    8.0|         0|z_Highly Rural/ R...|\n",
      "|829101238|       0|01DEC59|39.0|       2|13.0|$15,098|     No|$140,954|    Yes|   z_F|<High School|z_Blue Collar|      32|Private|  $5,400|  6|     z_SUV|     no|      $0|       0|     No|      1|     $0|    1.0|         0|z_Highly Rural/ R...|\n",
      "+---------+--------+-------+----+--------+----+-------+-------+--------+-------+------+------------+-------------+--------+-------+--------+---+----------+-------+--------+--------+-------+-------+-------+-------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_postgres = spark.read.jdbc(url=postgres_url, table=postgres_table_name, properties=postgres_properties)\n",
    "df_postgres.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- POLICY_NUMBER: long (nullable = true)\n",
      " |-- KIDSDRIV: long (nullable = true)\n",
      " |-- BIRTH: string (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- HOMEKIDS: long (nullable = true)\n",
      " |-- YOJ: double (nullable = true)\n",
      " |-- INCOME: string (nullable = true)\n",
      " |-- PARENT1: string (nullable = true)\n",
      " |-- HOME_VAL: string (nullable = true)\n",
      " |-- MSTATUS: string (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- EDUCATION: string (nullable = true)\n",
      " |-- OCCUPATION: string (nullable = true)\n",
      " |-- TRAVTIME: long (nullable = true)\n",
      " |-- CAR_USE: string (nullable = true)\n",
      " |-- BLUEBOOK: string (nullable = true)\n",
      " |-- TIF: long (nullable = true)\n",
      " |-- CAR_TYPE: string (nullable = true)\n",
      " |-- RED_CAR: string (nullable = true)\n",
      " |-- OLDCLAIM: string (nullable = true)\n",
      " |-- CLM_FREQ: long (nullable = true)\n",
      " |-- REVOKED: string (nullable = true)\n",
      " |-- MVR_PTS: long (nullable = true)\n",
      " |-- CLM_AMT: string (nullable = true)\n",
      " |-- CAR_AGE: double (nullable = true)\n",
      " |-- CLAIM_FLAG: long (nullable = true)\n",
      " |-- URBANICITY: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename column from \"ID\" to \"policy_number\"\n",
    "df_postgres = df_postgres.withColumnRenamed(\"ID\", \"POLICY_NUMBER\")\n",
    "df_postgres.printSchema()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-------+----+--------+----+-------+-------+--------+-------+------+------------+-----------+--------+-------+--------+---+----------+-------+--------+--------+-------+-------+-------+-------+----------+-------------------+\n",
      "|POLICY_NUMBER|KIDSDRIV|  BIRTH| AGE|HOMEKIDS| YOJ| INCOME|PARENT1|HOME_VAL|MSTATUS|GENDER|   EDUCATION| OCCUPATION|TRAVTIME|CAR_USE|BLUEBOOK|TIF|  CAR_TYPE|RED_CAR|OLDCLAIM|CLM_FREQ|REVOKED|MVR_PTS|CLM_AMT|CAR_AGE|CLAIM_FLAG|         URBANICITY|\n",
      "+-------------+--------+-------+----+--------+----+-------+-------+--------+-------+------+------------+-----------+--------+-------+--------+---+----------+-------+--------+--------+-------+-------+-------+-------+----------+-------------------+\n",
      "|    501699878|       0|31DEC58|40.0|       1|16.0|$66,987|     No|$236,897|    Yes|     F|   Bachelors|    Manager|      28|Private| $12,200| 13|Sports Car|     no|  $8,216|       3|     No|      6|     $0|   11.0|         0|Highly Urban/ Urban|\n",
      "|    624637727|       0|17NOV40|58.0|       0|14.0|$20,473|     No|      $0|     No|     F|   Bachelors| Home Maker|      52|Private| $17,850|  1|   Minivan|     no|      $0|       0|     No|      0|     $0|    8.0|         0|Highly Rural/ Rural|\n",
      "|    829101238|       0|01DEC59|39.0|       2|13.0|$15,098|     No|$140,954|    Yes|     F|<High School|Blue Collar|      32|Private|  $5,400|  6|       SUV|     no|      $0|       0|     No|      1|     $0|    1.0|         0|Highly Rural/ Rural|\n",
      "+-------------+--------+-------+----+--------+----+-------+-------+--------+-------+------+------------+-----------+--------+-------+--------+---+----------+-------+--------+--------+-------+-------+-------+-------+----------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Specify the column to be modified\n",
    "columns_to_modify = [\"MSTATUS\", \"GENDER\", \"EDUCATION\", \"OCCUPATION\", \"CAR_TYPE\", \"URBANICITY\"]\n",
    "# Modify string values by removing \"z_\"\n",
    "for column in columns_to_modify:\n",
    "    df_postgres = df_postgres.withColumn(column, regexp_replace(col(column), \"^z_\", \"\"))\n",
    "\n",
    "df_postgres.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8754"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_postgres.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2. load df_postgres to hive table\n",
    "# Create database\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS hocinedb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hocinedb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y4/h7s1_2k959z8nfw5xqv11nmr0000gn/T/ipykernel_42408/2374857337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create Hive Internal table over project1db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_postgres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'overwrite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhocinedb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarinsuaranceclaim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Read Hive table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hocinedb' is not defined"
     ]
    }
   ],
   "source": [
    " #Hive database and table names\n",
    "hive_database_name = \"hocinedb\"\n",
    "hive_table_name = \"carInsurance\"\n",
    "\n",
    "# Create Hive Internal table over project1db\n",
    "df_postgres.write.mode('overwrite').saveAsTable(hocinedb.carinsuaranceclaim)\n",
    "\n",
    "# Read Hive table\n",
    "df = spark.read.table(hocinedb.carinsuaranceclaim)\n",
    "df.show(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4283840756.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/y4/h7s1_2k959z8nfw5xqv11nmr0000gn/T/ipykernel_42408/4283840756.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    existing_hive_data.show(3)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "existing_hive_data = spark.read.table(\"{}.{}\".table(\"project1db.carinsuranceclaims\")\n",
    "existing_hive_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
